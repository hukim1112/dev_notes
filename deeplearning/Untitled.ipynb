{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing data with Tensorflow tf.data API\n",
    "\n",
    "tf.data는 간단한 수준에서 복잡한 수준까지의 Input pipeline을 구성할 수 있도록 하는 API이다. 구체적으로 제공하는 기능은 다음과 같다.\n",
    "\n",
    "## 1. tf.data.Dataset\n",
    "\n",
    "tf.data.Dataset은 연속된 element 집합으로, 각각의 element가 Tensor object로 구성되어있다. 이때 각각의 element는 Training을 위한 data와 label의 pair로 볼 수 있을 것이다.\n",
    "\n",
    "크게 다음과 같은 구성을 가진다.\n",
    "\n",
    "- Creating source : 다수의 tf.Tensor object로부터 dataset을 구성한다.\n",
    "\n",
    "  e.g : Dataset.from_tensor_slices()\n",
    "\n",
    "- Applying a transformation : 하나 또는 여러 개의 dataset object들로부터 새로운 dataset을 구성한다.\n",
    "\n",
    "  e.g : Dataset.batch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of data source\n",
    "1. tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices() :\n",
    "   memory 상의 tensor들로 dataset을 만드는 경우\n",
    "2. tf.data.TFRecordDataset :\n",
    "   Disk 상의 file들로 dataset을 만드는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1 : \n",
      "<dtype: 'float32'>\n",
      "(10,)\n",
      "dataset2 : \n",
      "(tf.float32, tf.int32)\n",
      "(TensorShape([]), TensorShape([Dimension(10)]))\n",
      "dataset3 : \n",
      "(tf.float32, (tf.float32, tf.int32))\n",
      "(TensorShape([Dimension(10)]), (TensorShape([]), TensorShape([Dimension(10)])))\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices( tf.random_uniform([4, 10], dtype = tf.float32) )\n",
    "print(\"dataset1 : \")\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices( \n",
    "    (tf.random_uniform( [4] ),\n",
    "     tf.random_uniform( [4, 10], maxval=100, dtype = tf.int32)))\n",
    "\n",
    "print(\"dataset2 : \")\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)\n",
    "    \n",
    "dataset3 = tf.data.Dataset.zip( (dataset1, dataset2) )\n",
    "print(\"dataset3 : \")\n",
    "print(dataset3.output_types)\n",
    "print(dataset3.output_shapes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. tf.data.Iterator\n",
    "\n",
    "tf.data.Iterator는 dataset으로부터 element들을 추출해내는 주된 방법을 제공한다. Iterator.get_next()이 실해오딜 때 dataset의 다음 element를 return하도록 구현되어 있다. 따라서 이 object는 input pipeline과 model 사이의 interface 역할을 한다.\n",
    "\n",
    "- Simple usage : \"one-shot iterator\"는 특정한 dataset에 대해서 한번 반복적으로 iteration을 수행한다. editting이 필요한 부분!!!\n",
    "- Sophisticated usage : Iterator.initializer operator를 통해서 여러 dataset들의 iterator들을 다시 초기화하여 같은 프로그램 내에서 여러 종류의 dataset에 대한 더욱 복잡한 형태의 model에 대한 data 입력을 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 다양한 source로부터의 입력\n",
    "   1. local file system\n",
    "   2. distributed file system\n",
    "   3. On-memory data\n",
    "   4. real-time data generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.6p3",
   "language": "python",
   "name": "tf1.6p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
